---
layout: post
title: Paradise Lost Data Visualization and Sentiment Analysis
---

_"Farewell happy fields_

_Where joy for ever dwells: Hail horrors, hail_

_Infernal world, and thou profoundest Hell_

_Receive thy new possessor: One who brings_

_A mind not to be changed by place or time._

_The mind is its own place, and in itself_

_Can make a Heaven of Hell, a Hell of Heaven."_

Book 1, Lines 249-255

<p align="center"> 
<img src="/assets/sentiment_pl/dore_satan_scaled.jpg" alt="Satan by Dore">
</p>

The language of Milton's _Paradise Lost_ invites an exploration of unique English composition and poetic style. Haynes (2000), among others, notes the poet's use of multilingual assets such as syntax and vocabulary, with deliberate attention to the narrator's and the characters' chosen rhetorical styles. His language is not Middle English, nor is it artificially archaicised like Spenser, nor is it exactly a King James biblical style. T.S. Elliot remarks that "Milton writes English like a dead language". This lends the work a unique challenge to analysis and understanding by natural language processing.

Sentiment analysis is the computational study of opinions, attitudes, and emotions expressed in (written) language, and is commonly used in natural language processing to determine the polarity of a text as expressing positive or negative sentiment. This project follows as: three sentiment analysis tools --- VADER; TextBLOB; NRC --- are applied to a spelling-normalized editin of John Milton's [_Paradise Lost_](https://www.paradiselost.org/8-search.html) and are compared for their respective sentiment metric scores. Each analyses' performance is averaged and given.

VADER's results (measured for: neg(ative); neu(tral); pos(itive); compound) follow as:

| | | **neg** | | **neu** | | **pos** | | **compound** |
|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|
| **mean**   | | 0.16 | | 0.58 | | 0.26 | | 0.67 | 
| **std**   | | 0.06 | | 0.04 | | 0.05 | | 0.78 | 
| **min**  | | 0.07 | | 0.52 | | 0.20 | | -1.00 | 
| **max**  | | 0.26 | | 0.65 | | 0.33 | | 1.00 | 

TextBLOB's results (measured for: polarity; objectivity) follow as:

| | | **polarity** | | **subjectivity** | 
|:--------|:--------|:--------|:--------|:--------|
| **mean**   | | 0.14 | | 0.53 |
| **std**   | | 0.06 | | 0.01 | 
| **min**  | | 0.05 | | 0.51 |
| **max**  | | 0.23 | | 0.55 | 

NRC's reults (measured for: fear; anger; anticipation; trust; surprise; positive; negative; sadness; disgust; joy) follow as:

| | | **fear** | | **anger** | | **anticipation** | | **trust** | | **surprise** | | **positive** | | **negative** | | **sadness** | | **disgust** | | **joy** |
|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|
| **mean**   | | 0.11 | | 0.07 | | 0.10 | | 0.12 | | 0.04 | | 0.20 | | 0.15 | | 0.07 | | 0.05 | | 0.09 |
| **std**   | | 0.03 | | 0.02 | | 0.02 | | 0.03 | | 0.01 | | 0.04 | | 0.03 | | 0.02 | | 0.01 | | 0.02 |
| **min**  | | 0.06 | | 0.04 | | 0.07 | | 0.08 | | 0.03 | | 0.13 | | 0.09 | | 0.04 | | 0.02 | | 0.06 |
| **max**  | | 0.15 | | 0.10 | | 0.12 | | 0.17 | | 0.05 | | 0.27 | | 0.19 | | 0.11 | | 0.08 | | 0.13 |

Across each sentiment analysis, we see a general trend towards an overall positivity score. Polarity extrema in TextBLOB relate as crossover points in VADER and NRC for positivity and negativity metrics, and do so such that minima of polarity scores in TextBLOB correlate with increasing negative scores and decreasing positivy scores in VADER and NRC, and vise versa. These emotional points in the narrative occur at the regions of Books I to III, Book VI, and Books IX to XI.

The visualization and sentiment analyses used in this project are available [here](https://github.com/deltaquebec/sentiment_paradise_lost).

## Introduction

_Paradise Lost_ is a sprawling English-language epic poem in blank verse by the 17th-century English poet John Milton. First published in ten books in 1667, the twelve book version (which is used in this analysis) came out in 1674. THe poem is (largely) a retelling of the third chapter of Genesis with the addition of flashbacks to Satan's rebellion in heaven as well as visions of later parts of the Bible. The poem was famously illustrated by French artist [Gustave Dor√©](https://en.wikipedia.org/wiki/Gustave_Dor%C3%A9), whose work is featured above.

The unique language of the poem offers a playground for NLP tasks such as sentiment analysis (as in this project); see [here](https://jonreeve.com/2016/07/paradise-lost-macroetymology/) for an etymological study of Milton's language in the poem. The goal of this project is twofold: 1) **practice with data exploration and visualization 2) **classify sentiment** across various NLP sentiment analysis tools. This project follows from the work of NBrisbon on [The Silmarillion](https://github.com/NBrisbon/Silmarillion-NLP), and so frequent comparison are made. The question remains: what sentiment analysis tools yield intuitive scores for sentiment?

## Methods

A searchable etext of _Paradise Lost_ is available [here](https://www.paradiselost.org/8-search.html), in which "Milton's archaic spelling has been modernized to faciltate search". Each book of the poem is saved as a text that is accessed and saved to a dataframe which are cleaned for stopwords, punctuation, and contractions, and is otherwise normalized to facilitate meaningful comparisons. 

Data visualization includes meaningful graphical representations of information in the text: POS frequencies; wordcloud representations; n-gram (mono-, bi-, tri-gram); average word length represented as probability density; lexical density (including normalization). Three sentiment analyis tools compute sentiment and emotion for each book of the poem: [VADER](https://github.com/cjhutto/vaderSentiment); [TextBLOB](https://textblob.readthedocs.io/en/dev/); [NRC](https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm).

To optimize completion time, each model was forced to perform on the GPU via the [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit). The GPU used is NVIDIA GeFORCE RTX 3070. Preliminary tests were done on the CPU: AMD Ryzen 7 3700X 8-Core Processor 3.59 GHz. Final results reported in this paper are those run on the GPU.

## Results

Using the tools of NLTK, we can track the frequency of word-use in the poem, which we can use to make a wordcloud. Wordclouds are visualizations of (text) data in which the size of a word represents its frequency or importance in that data. Wordclouds are handy for visualization-at-a-glance, and have the enjoyable consequence of making a report more lively. They are useful for qualitative judgments, but inherently give no numerical information with which to work; a cursory inspection of the wordcloud can give hint as to the subject matter of the text.

<p align="center">
<img src="/assets/sentiment_pl/vis_data_cloud.png" alt="wordcloud visualization">
</p>

n-gram analyses for n={1, 2, 3} is visualized below. [n-grams](https://web.stanford.edu/~jurafsky/slp3/3.pdf) track the frquency in which (word) tokens appear. 1-grams (monograms) refer to the frequency in which single word tokens appear; 2-grams (bigrams) refer to the frequency in which two word tokens appear together; 3-grams (trigrams) refer to the frequency in which three word tokens appear together. Roughly, such frequencies will follow a [Zipf-like distribution](https://web.archive.org/web/20021010193014/http://linkage.rockefeller.edu/wli/zipf/). n-grams are useful in that they tell us exactly word distributions (once appropriately filtered). Word pairings are exceptionally useful in many contexts, not limited to sentiment. Reconstruction of broken or incomplete texts, for example, and auto-correct are applications of n-grams. The n-gram distributions are plotted accordingly.

<p align="center">
<img src="/assets/sentiment_pl/vis_data_n_gram.png" alt="n-gram visualization" width="1400" >
</p>

The average word length is represented by a _probability density_, the values of which may be greater than 1; the distribution itself, however, will integrate to 1. The values of the y-axis, then, are useful for relative comparisons between categories. Converting to a probability (in which the bar heights sum to 1) in the code is simply a matter of changing the argument stat='density' to stat='probability', which is essentially equivalent to finding the area under the curve for a specific interval. See [this article](https://towardsdatascience.com/histograms-and-density-plots-in-python-f6bda88f5ac0) for more details. Here, Milton is fairly consistent in his word-length for lexical words. While attempted to fit to a gaussian, the distribution follows with an average of 5.57.

<p align="center">
<img src="/assets/sentiment_pl/vis_data_leng.png" alt="average word length"
</p>
  
Lexical densitity (or lexical diversity) is related as the lexical words of a text (content words such as nouns, adjectives, adverbs, verbs) divided by the total number of words. This relationship indicates the content words per total in a text. This number can be normailzed by using the size of the smallest text (word count 2824 --- the length of the shortest chapter) instead of the true total. This allows for a scaled comparison.
  
Milton is fairly consistent in his lexical inventory, and has a relatively high inventory of lexical items. The range of scores is [0, 1]; higher scores indicate higher lexical density. The average across all books is 0.51 (SD = 0.03) with (min,max) = (0.45,0.57), and the average across all books for the normalized data is 0.56 (SD = 0.02) with (min,max) = (0.53,0.59). Written forms of human communication in the English language typically have lexical densities above 0.40, while spoken forms tend to have lexical densities below 0.40 (Castello 2008). In a survey of historical texts by Michael Stubbs (1996), the typical lexical density of fictional literature ranged between 0.40 and 0.54, while non-fiction ranged between 0.40 and 0.65. 
  
<p align="center">
<img src="/assets/sentiment_pl/vis_data_dens.png" alt="lexical density"
</p>
  
